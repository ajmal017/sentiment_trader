{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Required for using keras-rl if not gives error\n","import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()\n","tf.test.gpu_device_name()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import pandas_ta\n","import numpy as np\n","\n","from gym import spaces\n","from gym_anytrading.envs import TradingEnv, StocksEnv, Actions, Positions \n","# from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from features import (\n","    generateTAFeatures,\n","    classifyColsByRanges,\n","    normalizeFeatures,\n",")\n","\n","import pickle\n","\n","PRICE_COLUMN = 'close'\n","POSITION_AS_OBSERVATION = True\n","\n","ranges_dict_path = 'data\\\\ranges_dict.pickle'\n","\n","data = pd.read_csv('.\\\\data\\\\featured_prices.csv', sep='\\t')\n","data = data.drop('Timestamp', axis=1)\n","with open(ranges_dict_path, 'rb') as f:\n","    ranges_dict = pickle.load(f)\n","\n","# data_csv = '.\\\\data\\\\prices_freq-min_2019-01-01_2019-03-28.csv'\n","# df = pd.read_csv(data_csv, sep='\\t', index_col='Timestamp', parse_dates=True)\n","# cols = ['open', 'high', 'low', 'close', 'volume']\n","# df = df[cols]\n","\n","# df = generateTAFeatures(df, [], None, True)\n","# ranges_dict = classifyColsByRanges(df)\n","# data = normalizeFeatures(df, ranges_dict)\n","# data.to_csv('data\\\\featured_prices.csv', sep='\\t', index_label='Timestamp')\n","\n","# with open(ranges_dict_path, 'wb') as f:\n","#     pickle.dump(ranges_dict, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FEATURE_COLUMNS = []\n","for key in ranges_dict:\n","    FEATURE_COLUMNS += ranges_dict[key]['cols'] if ranges_dict[key]['normalize'] else []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diff_cols = len(ranges_dict['prices']['cols']) - len(FEATURE_COLUMNS) - int(POSITION_AS_OBSERVATION)\n","print(f'Difference of {diff_cols} columns between prices cols and normalized cols')\n","print('In order to use Group Normalization Layer with 2 groups, both groups should be equal and sorted to be one first and then the other.')\n","\n","if diff_cols > 0:\n","    remove_cols = ['LR_14']\n","    print(f'The following columns are going to be removed: {remove_cols}')\n","    prices_cols = [col for col in ranges_dict['prices']['cols'] if col not in remove_cols]\n","else:\n","    prices_cols = ranges_dict['prices']['cols']\n","\n","FEATURE_COLUMNS = prices_cols + FEATURE_COLUMNS\n","\n","# Make sure that PRICE_COL is in data\n","ALL_COLS = PRICE_COLUMN if PRICE_COLUMN not in FEATURE_COLUMNS else []\n","ALL_COLS += FEATURE_COLUMNS\n","\n","# Set the columns used in data PRICE_COL + FEATURE_COLS\n","data = data[ALL_COLS]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["assert not np.isinf(data).any(1).any(), data[np.isinf(data).any(1)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Drop columns which have all columns as NaN\n","remove_cols = data.dtypes[data.isnull().all()].index\n","if len(remove_cols) > 0:\n","    data = data.drop(remove_cols, axis=1)\n","    print(f'The following columns have been removed: {list(remove_cols)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Drop rows which have at least one NaN\n","print(f'Dropping {data.isnull().any(axis=1).sum()} rows because of NaN values')\n","data = data[data.notnull().all(axis=1)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["unit_factor = 60*24*30 # months \n","print(f'Data for {len(data.index) / unit_factor:.3f} units')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_time = 2\n","gap_time = 0.3\n","test_time = len(data.index) / unit_factor - train_time - gap_time\n","\n","train_end = int(train_time * unit_factor)\n","test_start = train_end + int(gap_time * unit_factor)\n","test_end = test_start + int(test_time * unit_factor)\n","\n","train = data.iloc[0:train_end, :]\n","test = data.iloc[test_start:test_end, :]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["steps_per_episode = 120"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prices_process_data(env):\n","    start = env.frame_bound[0] - env.window_size\n","    end = env.frame_bound[1]\n","    prices = env.df.loc[:, PRICE_COLUMN].to_numpy()[start:end]\n","    signal_features = env.df[FEATURE_COLUMNS].to_numpy()[start:end]\n","    return prices, signal_features\n","\n","# TODO: Normalize somehow the reward to be more standard between runs, independent on the data is processing\n","# TODO: Plot training info during training to be able to track it\n","class OwnEnv(StocksEnv):\n","    _process_data = prices_process_data\n","\n","    def __init__(self, df, window_size, frame_bound, steps_per_episode, is_training, position_as_observation=True, constant_step=False, min_steps_per_episode=2, seed=None):\n","        super().__init__(df, window_size, frame_bound)\n","        \n","        if min_steps_per_episode <= 0:\n","            raise ValueError(f'min_steps_per_episode must be bigger than 0')\n","\n","        self.seed(seed)\n","        self.steps_per_episode = steps_per_episode\n","        self.max_steps_per_episode = steps_per_episode\n","        self.min_steps_per_episode = min_steps_per_episode\n","        self.is_training = is_training\n","\n","        self.trade_fee_bid_percent = 0.0 # 0.01  # unit\n","        self.trade_fee_ask_percent = 0.0 # 0.005  # unit\n","\n","        self.position_as_observation = position_as_observation\n","        self.shape = (window_size, self.signal_features.shape[1] + int(position_as_observation))\n","        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float32)\n","\n","        self.constant_step = constant_step\n","\n","    def reset(self, start_tick=None):\n","        if not self.constant_step:\n","            self.steps_per_episode = self.np_random.randint(self.max_steps_per_episode - self.min_steps_per_episode) + self.min_steps_per_episode\n","\n","        if self.is_training:\n","            if start_tick is None:\n","                self._start_tick = min(\n","                    self.np_random.randint(self.frame_bound[1] - 1 - self.steps_per_episode) + self.window_size,\n","                    self.frame_bound[1] - self.steps_per_episode - 1\n","                )\n","            else:\n","                self._start_tick = start_tick\n","            self._end_tick = min(\n","                self._start_tick + self.steps_per_episode,\n","                self.frame_bound[1] - 1\n","            )\n","            \n","        return super().reset()\n","\n","    def step(self, action):\n","        observation, reward, done, info = super().step(action)\n","        #print(observation, done, info)\n","\n","        # TODO: Check if better use only final reward or step_rewards\n","        reward = 0\n","        if done:\n","            max_possible_revenue = self.max_possible_profit() - 1\n","            revenue = (info['total_profit'] - 1)\n","            if max_possible_revenue > 0:\n","                if revenue >= 0:\n","                    reward = revenue / max_possible_revenue\n","                else:\n","                    reward = 0\n","            elif max_possible_revenue < 0:\n","                # reward = max_possible_revenue / revenue\n","                reward = 0\n","            else:\n","                reward = revenue\n","            # TODO: Should this be modified?\n","            # info = dict(\n","            #     total_reward = self._total_reward,\n","            #     total_profit = self._total_profit,\n","            #     position = self._position.value\n","            # )\n","\n","        # Only for tracking of training\n","        # if done:    \n","        #     print(info['total_profit'] - 1, self.max_possible_profit() - 1)\n","            \n","        return observation, reward, done, info\n","\n","    def _get_observation(self):\n","        features = self.signal_features[(self._current_tick-self.window_size):self._current_tick]\n","        \n","        if self.position_as_observation:\n","            positions = np.expand_dims(\n","                np.array(\n","                    list(\n","                        map(\n","                            lambda position: position.value if position is not None else 0,\n","                            self._position_history[-self.window_size:]\n","                        )\n","                    )\n","                ),\n","                axis=1\n","            )\n","            return np.append(\n","                features,\n","                positions,\n","                axis=1\n","            )\n","        else:\n","            return features\n","\n","window_size = 3\n","\n","#### ONLY FOR TESTING OVERFITING\n","\n","# data = data[0:steps_per_episode*2]\n","\n","##############################################\n","\n","train_env = OwnEnv(\n","    df=train,\n","    window_size=window_size,\n","    frame_bound=(window_size, len(train)),\n","    steps_per_episode=steps_per_episode,\n","    is_training=True,\n","    position_as_observation=POSITION_AS_OBSERVATION,\n",")\n","\n","test_env = OwnEnv(\n","    df=test,\n","    window_size=window_size,\n","    frame_bound=(window_size, len(test)),\n","    steps_per_episode=steps_per_episode,\n","    is_training=False,\n","    position_as_observation=POSITION_AS_OBSERVATION,\n",")\n","\n","#env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)\n","# env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Flatten, LSTM, Input, Reshape, Cropping2D\n","from tensorflow.keras.regularizers import L1L2\n","\n","from tensorflow_addons.layers import GroupNormalization\n","\n","# TODO: Look at initialization/normalization to start with 50/50 model\n","# Next, we build a very simple model.\n","activation = 'relu'\n","regularizer = None# L1L2(0.1, 0.1)\n","\n","model = Sequential()\n","if window_size > 1:\n","    model.add(Input((window_size, ) + train_env.observation_space.shape))\n","    model.add(Cropping2D(cropping=((-1, 0), (0, 0))))\n","    model.add(Reshape((window_size, train_env.observation_space.shape[1])))\n","    # model.add(LayerNormalization(axis=1, center=True, scale=True))\n","    model.add(GroupNormalization(groups=2, axis=2))\n","    model.add(LSTM(8, kernel_regularizer=regularizer, return_sequences=True))\n","    model.add(LSTM(8, kernel_regularizer=regularizer))\n","\n","else:\n","    model.add(Flatten(input_shape=(window_size,) + train_env.observation_space.shape))\n","    model.add(Dense(64, activation='relu', kernel_regularizer=regularizer))\n","    # model.add(Dense(1024, activation='relu', kernel_regularizer=regularizer))\n","    model.add(Dense(64, activation='relu', kernel_regularizer=regularizer))\n","\n","model.add(Dense(train_env.action_space.n, kernel_regularizer=regularizer))\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n","\n","callbacks = [tensorboard_callback]\n","callbacks = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from rl.agents.dqn import DQNAgent\n","from rl.policy import BoltzmannQPolicy, SoftmaxPolicy\n","from rl.memory import SequentialMemory\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","memory_steps = 100000\n","memory_steps = min(memory_steps, len(train_env.df) - 1)\n","# Finally, we configure and compile our agent. You can use every built-in tensorflow.keras optimizer and\n","# even the metrics!\n","memory = SequentialMemory(limit=memory_steps, window_length=window_size)\n","policy = BoltzmannQPolicy()\n","# policy = EpsGreedyQPolicy()\n","# dqn = DQNAgent(model=model, nb_actions=env.action_space.n, memory=memory, nb_steps_warmup=10, target_model_update=1e-2, policy=policy)\n","dqn = DQNAgent(model=model, nb_actions=train_env.action_space.n, memory=memory, target_model_update=1e-2, nb_steps_warmup=window_size, policy=policy, gamma=1, processor=None)\n","dqn.compile(Adam(learning_rate=1e-3, clipvalue=0.1), metrics=['mae'])"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend"]},"outputs":[],"source":["# Okay, now it's time to learn something! We visualize the training here for show, but this\n","# slows down training quite a lot. You can always safely abort the training prematurely using\n","# Ctrl + C.\n","history = dqn.fit(train_env, nb_steps=memory_steps, visualize=False, verbose=2, callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rewards = history.history['episode_reward']\n","rewards_df = pd.DataFrame(rewards)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure()\n","x = range(len(rewards))\n","plt.plot(x, rewards)\n","plt.plot(x, rewards_df.rolling(25).mean())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["env_data = test\n","\n","all_envs = {}\n","\n","full_env = OwnEnv(\n","    df=env_data,\n","    window_size=window_size,\n","    frame_bound=(window_size, len(env_data)),\n","    steps_per_episode=len(env_data) - window_size, # steps_per_episode,\n","    constant_step=True,\n","    is_training=False,\n","    position_as_observation=POSITION_AS_OBSERVATION,\n",")\n","all_envs['Full test'] = full_env\n","\n","#TODO: For the is_training=True we have to make that all executions are using same cases\n","step_env = OwnEnv(\n","    df=env_data,\n","    window_size=window_size,\n","    frame_bound=(window_size, len(env_data)),\n","    steps_per_episode=steps_per_episode,\n","    constant_step=True,\n","    is_training=True,\n","    position_as_observation=POSITION_AS_OBSERVATION,\n",")\n","all_envs[f'Test step of {steps_per_episode}'] = step_env\n","\n","large_step_env = OwnEnv(\n","    df=env_data,\n","    window_size=window_size,\n","    frame_bound=(window_size, len(env_data)),\n","    steps_per_episode=10 * steps_per_episode,\n","    constant_step=True,\n","    is_training=True,\n","    position_as_observation=POSITION_AS_OBSERVATION,\n",")\n","all_envs[f'Test step of {10*steps_per_episode}'] = large_step_env\n","\n","small_step_env = OwnEnv(\n","    df=env_data,\n","    window_size=window_size,\n","    frame_bound=(window_size, len(env_data)),\n","    steps_per_episode=int(0.1 * steps_per_episode),\n","    constant_step=True,\n","    is_training=True,\n","    position_as_observation=POSITION_AS_OBSERVATION,\n",")\n","all_envs[f'Test step of {int(0.1 * steps_per_episode)}'] = small_step_env"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runAllTestEnv(all_envs, select_action_func, iterations=None, use_steps=False, use_observation=False, use_model=False, **kwargs):\n","    if type(all_envs) is list:\n","        all_envs = dict(zip([f'Env_{i}' for i in range(len(all_envs))], all_envs))\n","\n","    if type(all_envs) is not dict:\n","        raise ValueError('all_envs should be dictionary of name and enviorment or a list of enviorments')\n","    else:\n","        for env_name, env in all_envs.items():\n","            print(f'Testing enviorment {env_name}:')\n","            runTestEnv(env, select_action_func, iterations=iterations, use_steps=use_steps, use_observation=use_observation, use_model=use_model, **kwargs)\n","            print('-'*50)\n","\n","def runTestEnv(env, select_action_func, iterations=None, use_steps=False, use_observation=False, use_model=False, **kwargs):\n","    if iterations is None:\n","        if env.is_training:\n","            iterations = int((env.frame_bound[1] - env.frame_bound[0]) / env.steps_per_episode)\n","        else:\n","            iterations = 1\n","    \n","    total_rewards = []\n","    total_profits = [] \n","\n","    start_tick = env.window_size\n","    for i in range(iterations):\n","        observation = env.reset(start_tick=start_tick)\n","        if use_model:\n","            done = False\n","            recent_observations = []\n","            recent_terminals = []\n","        step = 0\n","        while True:\n","            if use_model:\n","                action = select_action_func(observation, recent_observations, recent_terminals, done, **kwargs)\n","            else:\n","                if use_observation:\n","                    if use_steps:\n","                        action = select_action_func(observation=observation, step=step, **kwargs)\n","                    else:\n","                        action = select_action_func(observation=observation, **kwargs)\n","                else:\n","                    if use_steps:\n","                        action = select_action_func(step=step, **kwargs)\n","                    else:\n","                        action = select_action_func(**kwargs)\n","\n","            observation, reward, done, info = env.step(action)\n","            \n","            if done:\n","                start_tick = env._current_tick\n","                break\n","\n","            step += 1\n","\n","        total_rewards.append(info['total_reward'])\n","        total_profits.append(info['total_profit'])\n","    \n","    print(f'Total rewards: {np.mean(total_rewards):.2f} ± {np.std(total_rewards):.3f} (mean ± std. dev. of {iterations} iterations)')\n","    print(f'Total profits: {(np.mean(total_profits) - 1):.2%} ± {np.std(total_profits):.3%} (mean ± std. dev. of {iterations} iterations)')\n","\n","    return total_rewards, total_profits"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend"]},"outputs":[],"source":["# Apply random policy on env\n","runAllTestEnv(all_envs, select_action_func=full_env.action_space.sample);"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying long term policy (buy at initial and do not sell) on env\n","\n","def always_buy_func():\n","    return  Actions.Buy.value\n","\n","runAllTestEnv(all_envs, select_action_func=always_buy_func);"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying baseline policy on env\n","\n","# Manual policy used as baseline\n","\n","rsi_col = 'RSI_14'\n","# rsi_col = 'Close_rsi'\n","rsi_index=FEATURE_COLUMNS.index(rsi_col)\n","\n","# RSI usually is between 0 and 100, here is normalized between -1 and 1\n","# The baseline strategy is buy at 30 and sell at 70 otherwise hold\n","def select_baseline_action(observation, rsi_thresh_buy=-0.6, rsi_thresh_sell=0.4, rsi_index=rsi_index):\n","    # Use only last observation\n","    obs = observation[-1]\n","\n","    position_value = int(obs[-1])\n","    rsi = obs[rsi_index]\n","\n","    if position_value == Positions.Short.value and rsi <= rsi_thresh_buy:\n","        action = Actions.Buy.value\n","    elif position_value == Positions.Long.value and rsi >= rsi_thresh_sell:\n","        action = Actions.Sell.value\n","    else:\n","        # Hold\n","        # if it was in short remain in short because is selling\n","        # if it was in long remain in long because is buying\n","        action = position_value\n","    \n","    return action\n","\n","runAllTestEnv(all_envs, select_action_func=select_baseline_action, use_observation=True, rsi_thresh_buy=0.3, rsi_thresh_sell=0.7);"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from rl.memory import zeroed_observation\n","\n","# Applying trained policy on env\n","\n","def get_recent_state(current_observation, recent_observations, recent_terminals, window_length):\n","        \"\"\"Return list of last observations\n","\n","        # Argument\n","            current_observation (object): Last observation\n","\n","        # Returns\n","            A list of the last observations\n","        \"\"\"\n","        # This code is slightly complicated by the fact that subsequent observations might be\n","        # from different episodes. We ensure that an experience never spans multiple episodes.\n","        # This is probably not that important in practice but it seems cleaner.\n","        state = [current_observation]\n","        idx = len(recent_observations) - 1\n","        for offset in range(0, window_length - 1):\n","            current_idx = idx - offset\n","            current_terminal = recent_terminals[current_idx - 1] if current_idx - 1 >= 0 else False\n","            if current_idx < 0 or current_terminal:\n","                # The previously handled observation was terminal, don't add the current one.\n","                # Otherwise we would leak into a different episode.\n","                break\n","            state.insert(0, recent_observations[current_idx])\n","        while len(state) < window_length:\n","            state.insert(0, zeroed_observation(state[0]))\n","        return state\n","\n","def select_model_action(observation, recent_observations, recent_terminals, done, window_size):\n","    obs = get_recent_state(observation, recent_observations, recent_terminals, window_size)\n","    obs = np.expand_dims(obs, axis=0)\n","    recent_observations.append(observation)\n","    recent_terminals.append(done)\n","    return np.argmax(model.predict(obs))\n","\n","runAllTestEnv(all_envs, select_action_func=select_model_action, use_model=True, window_size=window_size);"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# After training is done, we save the final weights.\n","dqn.save_weights('dqn_{}_weights.h5f'.format('prices'), overwrite=True)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37664bitcryptotraderconda69cc994ed1944dadbb053620b665a6b3","display_name":"Python 3.7.6 64-bit ('crypto_trader': conda)"}}}