{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import functools\n","\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["LABEL_COLUMN = 'Close'\n","BATCH_SIZE = 10\n","WINDOW_SIZE = 5\n","EPOCHS = 1\n","train_file_path = 'data/all_data.csv'\n","\n","def get_dataset(file_path, **kwargs):\n","  dataset = tf.data.experimental.make_csv_dataset(\n","      file_path,\n","      shuffle=False,\n","      #prefetch_buffer_size=2,\n","      ignore_errors=True, \n","      **kwargs)\n","  return dataset\n","\n","NUMERIC_FEATURES = [\n","    #'Close',\n","    'Volume_BTC',\n","    'replies_sum',\n","    'replies_mean',\n","    'likes_sum',\n","    'likes_mean',\n","    'retweets_sum',\n","    'retweets_mean',\n","    'Negative_mean',\n","    'Negative_replies_mean',\n","    'Negative_likes_mean',\n","    'Negative_retweets_mean',\n","    'Neutral_mean',\n","    'Neutral_replies_mean',\n","    'Neutral_likes_mean',\n","    'Neutral_retweets_mean',\n","    'Compound_mean',\n","    'Compound_replies_mean',\n","    'Compound_likes_mean',\n","    'Compound_retweets_mean',\n","    'Polarity_mean',\n","    'Polarity_replies_mean',\n","    'Polarity_likes_mean',\n","    'Polarity_retweets_mean',\n","    'Subjectivity_mean',\n","    'Subjectivity_replies_mean',\n","    'Subjectivity_likes_mean',\n","    'Subjectivity_retweets_mean',\n","]\n","\n","BOOLEAN_FEATURES = [\n","    'no_tweets',\n","    'no_data'\n","]\n","\n","CATEGORICAL_FEATURES = []\n","\n","features_columns = NUMERIC_FEATURES + CATEGORICAL_FEATURES + BOOLEAN_FEATURES\n","select_columns = [LABEL_COLUMN] + features_columns\n","#select_columns = [LABEL_COLUMN] + NUMERIC_FEATURES# + CATEGORICAL_FEATURES + BOOLEAN_FEATURES\n","\n","ds = get_dataset(train_file_path, field_delim='\\t', select_columns=select_columns, batch_size=WINDOW_SIZE, num_epochs=EPOCHS, label_name=LABEL_COLUMN)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class PackNumericFeatures(object):\n","  def __init__(self, names):\n","    self.names = names\n","\n","  def __call__(self, features, labels):\n","    numeric_features = [features.pop(name) for name in self.names]\n","    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n","    numeric_features = tf.stack(numeric_features, axis=-1)\n","    #features['numeric'] = numeric_features\n","\n","    #return features, labels\n","    return numeric_features, labels\n","\n","ds = ds.map(\n","    PackNumericFeatures(features_columns)\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n","  windows = ds.unbatch().window(window_size, shift=shift, stride=stride)\n","\n","  def sub_to_batch(sub):\n","    return sub.batch(window_size, drop_remainder=True)\n","\n","  windows = windows.flat_map(sub_to_batch)\n","  return windows"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["labels_ds = ds.unbatch().skip(WINDOW_SIZE).map(lambda x,y: y).batch(1)\n","window_feature_ds = make_window_dataset(ds.map(lambda x,y: x), window_size=WINDOW_SIZE, shift=1, stride=1)\n","\n","final_ds = tf.data.Dataset.zip((window_feature_ds, labels_ds)).batch(BATCH_SIZE, drop_remainder=True).shuffle(1000)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tf.Tensor(\n[[ 0.  ]\n [ 0.  ]\n [ 0.  ]\n [ 0.  ]\n [ 0.  ]\n [-0.32]\n [ 0.  ]\n [ 0.  ]\n [ 0.  ]\n [ 0.  ]], shape=(10, 1), dtype=float32)\ntf.Tensor(\n[[[12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  1.        0.2      ...  0.        0.        0.      ]]\n\n [[12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  1.        0.2      ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]]\n\n [[12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  1.        0.2      ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]]\n\n ...\n\n [[12.066947  0.        0.       ...  0.4       0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        1.        0.      ]]\n\n [[12.066947  0.        0.       ...  0.        0.        0.      ]\n  [12.066947  0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        1.        0.      ]\n  [10.        0.        0.       ...  0.        0.        0.      ]]\n\n [[12.066947  0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        1.        0.      ]\n  [10.        0.        0.       ...  0.        0.        0.      ]\n  [10.        0.        0.       ...  0.        0.        0.      ]]], shape=(10, 5, 29), dtype=float32)\n"}],"source":["for example, label in final_ds.take(1):\n","    print(label)\n","    print(example)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","desc = pd.read_csv(train_file_path, sep='\\t', usecols=NUMERIC_FEATURES).describe()\n","\n","MEAN = np.array(desc.T['mean'])\n","STD = np.array(desc.T['std'])\n","\n","def normalize_numeric_data(data, mean, std):\n","  # Center the data\n","  return (data-mean)/std\n","\n","normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n","\n","#numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n","numeric_column = tf.feature_column.sequence_numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n","numeric_columns = [numeric_column]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["CATEGORIES = {\n","    # 'class' : ['First', 'Second', 'Third']\n","}\n","categorical_columns = []\n","for feature, vocab in CATEGORIES.items():\n","  #cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n","  #      key=feature, vocabulary_list=vocab)\n","  cat_col = tf.feature_column.sequence_categorical_column_with_vocabulary_list(\n","        key=feature, vocabulary_list=vocab)\n","  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["boolean_columns = []\n","for feature in BOOLEAN_FEATURES:\n","    #bool_col = tf.feature_column.numeric_column(key=feature, default_value=0, dtype=tf.int8)\n","    bool_col = tf.feature_column.sequence_numeric_column(key=feature, default_value=0, dtype=tf.int8)\n","    boolean_columns.append(bool_col)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'items'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-10-e3a9d2b9f0e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         feature_inputs.update(\n\u001b[0;32m     10\u001b[0m             {\n","\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'items'"]}],"source":["#preprocessing_layer = tf.keras.layers.DenseFeatures(numeric_columns+categorical_columns+boolean_columns)\n","#preprocessing_layer = tf.keras.experimental.SequenceFeatures(numeric_columns+categorical_columns+boolean_columns)\n","preprocessing_layer = tf.keras.experimental.SequenceFeatures(numeric_columns)\n","\n","feature_inputs = {}\n","\n","for x, y in ds.take(1):\n","    for key, value in x.items():\n","        feature_inputs.update(\n","            {\n","                key: tf.keras.Input(value.shape, dtype=value.dtype, name=key)\n","            }\n","        )\n","        print(key, value.shape, value.dtype)\n","\n","print(feature_inputs)\n","\n","#inputs = preprocessing_layer(feature_inputs)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["model = tf.keras.models.Sequential(\n","    [\n","        #preprocessing_layer,\n","        #tf.keras.layers.Reshape((WINDOW_SIZE, len(select_columns))),\n","        tf.keras.layers.LSTM(32,\n","                               return_sequences=True,),\n","                               #input_shape=(30, BATCH_SIZE)),\n","        tf.keras.layers.LSTM(16, activation='relu'),\n","        tf.keras.layers.Dense(1)\n","    ]\n",")\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"6673/6673 [==============================] - 72s 11ms/step - loss: 14.5937\n"},{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x1781ffb8b48>"},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(final_ds, verbose=1)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_2 (LSTM)                multiple                  7936      \n_________________________________________________________________\nlstm_3 (LSTM)                multiple                  3136      \n_________________________________________________________________\ndense_1 (Dense)              multiple                  17        \n=================================================================\nTotal params: 11,089\nTrainable params: 11,089\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37664bitcryptotraderconda69cc994ed1944dadbb053620b665a6b3","display_name":"Python 3.7.6 64-bit ('crypto_trader': conda)"}}}