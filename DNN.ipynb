{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import functools\n","\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["LABEL_COLUMN = 'Close'\n","BATCH_SIZE = 32\n","WINDOW_SIZE = 24\n","EPOCHS = 1\n","train_file_path = 'data/all_data.csv'\n","#train_file_path = 'data/reduced_data.csv'\n","\n","def get_dataset(file_path, **kwargs):\n","  dataset = tf.data.experimental.make_csv_dataset(\n","      file_path,\n","      shuffle=False,\n","      #prefetch_buffer_size=2,\n","      ignore_errors=True, \n","      **kwargs)\n","  return dataset\n","\n","NUMERIC_FEATURES = [\n","    #'Close',\n","    'Close_diff',\n","    'Close_moving_average',\n","    'Volume_BTC',\n","    'replies_sum',\n","    'replies_mean',\n","    'likes_sum',\n","    'likes_mean',\n","    'retweets_sum',\n","    'retweets_mean',\n","    'Negative_mean',\n","    'Negative_replies_mean',\n","    'Negative_likes_mean',\n","    'Negative_retweets_mean',\n","    'Neutral_mean',\n","    'Neutral_replies_mean',\n","    'Neutral_likes_mean',\n","    'Neutral_retweets_mean',\n","    'Compound_mean',\n","    'Compound_replies_mean',\n","    'Compound_likes_mean',\n","    'Compound_retweets_mean',\n","    'Polarity_mean',\n","    'Polarity_replies_mean',\n","    'Polarity_likes_mean',\n","    'Polarity_retweets_mean',\n","    'Subjectivity_mean',\n","    'Subjectivity_replies_mean',\n","    'Subjectivity_likes_mean',\n","    'Subjectivity_retweets_mean',\n","]\n","\n","BOOLEAN_FEATURES = [\n","    'no_tweets',\n","    'no_data'\n","]\n","\n","CATEGORICAL_FEATURES = []\n","\n","features_columns = NUMERIC_FEATURES + CATEGORICAL_FEATURES + BOOLEAN_FEATURES\n","select_columns = [LABEL_COLUMN] + features_columns\n","#select_columns = [LABEL_COLUMN] + NUMERIC_FEATURES# + CATEGORICAL_FEATURES + BOOLEAN_FEATURES\n","\n","ds = get_dataset(train_file_path, field_delim='\\t', select_columns=select_columns, batch_size=WINDOW_SIZE, num_epochs=EPOCHS, label_name=LABEL_COLUMN)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["class PackNumericFeatures(object):\n","  def __init__(self, names):\n","    self.names = names\n","\n","  def __call__(self, features, labels):\n","    numeric_features = [features.pop(name) for name in self.names]\n","    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n","    numeric_features = tf.stack(numeric_features, axis=-1)\n","    #features['numeric'] = numeric_features\n","\n","    #return features, labels\n","    return numeric_features, labels\n","\n","ds = ds.map(\n","    PackNumericFeatures(features_columns)\n",")"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n","  windows = ds.unbatch().window(window_size, shift=shift, stride=stride)\n","\n","  def sub_to_batch(sub):\n","    return sub.batch(window_size, drop_remainder=True)\n","\n","  windows = windows.flat_map(sub_to_batch)\n","  return windows"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["labels_ds = ds.unbatch().skip(WINDOW_SIZE).map(lambda x,y: y).batch(1)\n","window_feature_ds = make_window_dataset(ds.map(lambda x,y: x), window_size=WINDOW_SIZE, shift=1, stride=1)\n","\n","final_ds = tf.data.Dataset.zip((window_feature_ds, labels_ds)).shuffle(100000).batch(BATCH_SIZE, drop_remainder=True)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tf.Tensor(\n[[   9.36]\n [ -41.81]\n [-111.84]\n [   3.84]\n [   1.89]\n [ -31.63]\n [ -48.32]\n [ 158.77]\n [  -6.86]\n [   1.13]\n [ -27.25]\n [ -46.02]\n [   6.72]\n [ -40.19]\n [  48.23]\n [  70.74]\n [  74.65]\n [   1.55]\n [  88.29]\n [ -27.1 ]\n [ -23.77]\n [ -20.27]\n [-211.28]\n [   4.8 ]\n [   0.3 ]\n [   2.32]\n [  31.13]\n [ -14.04]\n [  -9.24]\n [  -7.92]\n [ -27.19]\n [ -65.78]], shape=(32, 1), dtype=float32)\ntf.Tensor(\n[[[1.9674013e+01 1.2000000e+01 4.0000000e+00 ... 5.6636673e-01\n   0.0000000e+00 0.0000000e+00]\n  [1.7817919e+00 0.0000000e+00 0.0000000e+00 ... 5.0000000e-01\n   0.0000000e+00 0.0000000e+00]\n  [2.2418001e+00 6.0000000e+00 2.1428572e-01 ... 2.3750000e-01\n   0.0000000e+00 0.0000000e+00]\n  ...\n  [3.7414718e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [2.0900793e+00 2.0000000e+00 1.0000000e+00 ... 9.1074677e-03\n   0.0000000e+00 0.0000000e+00]\n  [2.0821960e+00 3.0000000e+00 3.0000000e+00 ... 1.0000000e+00\n   0.0000000e+00 0.0000000e+00]]\n\n [[9.4021482e+00 9.3000000e+01 1.6315789e+00 ... 4.5767197e-01\n   0.0000000e+00 0.0000000e+00]\n  [1.5721300e+00 4.6000000e+01 1.1219512e+00 ... 4.2274073e-01\n   0.0000000e+00 0.0000000e+00]\n  [5.4251904e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  ...\n  [1.7683405e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [1.1986027e+00 0.0000000e+00 0.0000000e+00 ... 3.1250000e-01\n   0.0000000e+00 0.0000000e+00]\n  [5.7230582e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]]\n\n [[8.9888172e+00 1.0000000e+01 1.9607843e-01 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [3.2805388e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [9.1379051e+00 5.0000000e+00 5.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  ...\n  [4.7108908e+00 7.0000000e+00 1.7073171e-01 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [1.2665859e+01 6.0000000e+00 1.5789473e-01 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [3.7052650e+01 1.7000000e+01 3.2692307e-01 ... 2.7399999e-01\n   0.0000000e+00 0.0000000e+00]]\n\n ...\n\n [[5.6720597e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [4.8102966e-01 4.0000000e+00 1.2903225e-01 ... 3.1666666e-01\n   0.0000000e+00 0.0000000e+00]\n  [9.2719263e-01 2.0000000e+00 6.4516127e-02 ... 3.7380952e-01\n   0.0000000e+00 0.0000000e+00]\n  ...\n  [7.9691851e-01 1.0000000e+00 3.0303031e-02 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [6.5442270e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [4.1112542e+00 0.0000000e+00 0.0000000e+00 ... 4.4565973e-01\n   0.0000000e+00 0.0000000e+00]]\n\n [[3.1444136e+01 3.0000000e+00 7.8947365e-02 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [4.3566290e-01 3.0000000e+00 5.6603774e-02 ... 2.7500001e-01\n   0.0000000e+00 0.0000000e+00]\n  [8.1998026e-01 1.0000000e+00 2.2222223e-02 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  ...\n  [5.5148373e+00 1.3000000e+01 1.3000000e+01 ... 4.1818181e-01\n   0.0000000e+00 0.0000000e+00]\n  [2.8411849e+00 6.0000000e+00 1.3043478e-01 ... 1.4000000e-01\n   0.0000000e+00 0.0000000e+00]\n  [2.5876760e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]]\n\n [[4.6364450e+00 0.0000000e+00 0.0000000e+00 ... 3.4999999e-01\n   0.0000000e+00 0.0000000e+00]\n  [6.8041909e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [5.5075186e-01 5.0000000e+00 8.9285716e-02 ... 3.3333335e-02\n   0.0000000e+00 0.0000000e+00]\n  ...\n  [2.5043457e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [8.4116821e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n   0.0000000e+00 0.0000000e+00]\n  [1.3650844e+00 2.0000000e+00 3.1250000e-02 ... 2.5000000e-01\n   0.0000000e+00 0.0000000e+00]]], shape=(32, 24, 29), dtype=float32)\n"}],"source":["for example, label in final_ds.take(1):\n","    print(label)\n","    print(example)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","desc = pd.read_csv(train_file_path, sep='\\t', usecols=NUMERIC_FEATURES).describe()\n","\n","MEAN = np.array(desc.T['mean'])\n","STD = np.array(desc.T['std'])\n","\n","def normalize_numeric_data(data, mean, std):\n","  # Center the data\n","  return (data-mean)/std\n","\n","normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n","\n","#numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n","numeric_column = tf.feature_column.sequence_numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n","numeric_columns = [numeric_column]"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["CATEGORIES = {\n","    # 'class' : ['First', 'Second', 'Third']\n","}\n","categorical_columns = []\n","for feature, vocab in CATEGORIES.items():\n","  #cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n","  #      key=feature, vocabulary_list=vocab)\n","  cat_col = tf.feature_column.sequence_categorical_column_with_vocabulary_list(\n","        key=feature, vocabulary_list=vocab)\n","  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["boolean_columns = []\n","for feature in BOOLEAN_FEATURES:\n","    #bool_col = tf.feature_column.numeric_column(key=feature, default_value=0, dtype=tf.int8)\n","    bool_col = tf.feature_column.sequence_numeric_column(key=feature, default_value=0, dtype=tf.int8)\n","    boolean_columns.append(bool_col)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'items'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-61-e3a9d2b9f0e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         feature_inputs.update(\n\u001b[0;32m     10\u001b[0m             {\n","\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'items'"]}],"source":["#preprocessing_layer = tf.keras.layers.DenseFeatures(numeric_columns+categorical_columns+boolean_columns)\n","#preprocessing_layer = tf.keras.experimental.SequenceFeatures(numeric_columns+categorical_columns+boolean_columns)\n","preprocessing_layer = tf.keras.experimental.SequenceFeatures(numeric_columns)\n","\n","feature_inputs = {}\n","\n","for x, y in ds.take(1):\n","    for key, value in x.items():\n","        feature_inputs.update(\n","            {\n","                key: tf.keras.Input(value.shape, dtype=value.dtype, name=key)\n","            }\n","        )\n","        print(key, value.shape, value.dtype)\n","\n","print(feature_inputs)\n","\n","#inputs = preprocessing_layer(feature_inputs)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["model = tf.keras.models.Sequential(\n","    [\n","        #preprocessing_layer,\n","        #tf.keras.layers.Reshape((WINDOW_SIZE, len(select_columns))),\n","        tf.keras.layers.LayerNormalization(axis=1, center=True, scale=True),\n","        tf.keras.layers.LSTM(64,\n","                               return_sequences=True,),\n","                               #input_shape=(30, BATCH_SIZE)),\n","        tf.keras.layers.LSTM(32, activation='relu'),\n","        tf.keras.layers.Dense(1)\n","    ]\n",")\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, clipvalue=1.0), loss='mae')"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"440/440 [==============================] - 16s 37ms/step - loss: 42.1479\n"},{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x179d967f748>"},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(final_ds, verbose=1)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlayer_normalization_5 (Layer multiple                  48        \n_________________________________________________________________\nlstm_22 (LSTM)               multiple                  7936      \n_________________________________________________________________\nlstm_23 (LSTM)               multiple                  3136      \n_________________________________________________________________\ndense_11 (Dense)             multiple                  17        \n=================================================================\nTotal params: 11,137\nTrainable params: 11,137\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37664bitcryptotraderconda69cc994ed1944dadbb053620b665a6b3","display_name":"Python 3.7.6 64-bit ('crypto_trader': conda)"}}}